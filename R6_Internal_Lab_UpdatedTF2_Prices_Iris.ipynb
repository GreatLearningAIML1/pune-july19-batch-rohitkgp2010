{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_Internal_Lab_UpdatedTF2_Prices_Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84Q8JfvaeZZ6"
      },
      "source": [
        "## Linear Classifier in TensorFlow \n",
        "Using Low Level API in Eager Execution mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "b51fa7be-abe8-4ae1-95ca-ff8b880035ca"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlKCTombENFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc65ea1b-45e1-4dbe-9232-2f444bddfce1"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mjtb-EMcm5K0",
        "colab": {}
      },
      "source": [
        "#Enable Eager Execution if using tensflow version < 2.0\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8eeb157-2e42-479d-c91d-2be79e8c617a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiObW4V4SIOz",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Resid6_NeuralNetworks/LabInternal/prices.csv\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1b989f9-e3f1-4f37-eda9-0a27e09f1120"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([u'date', u'symbol', u'open', u'close', u'low', u'high', u'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCY7M6SiyabS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e2ec6c98-28d5-4bfd-e3e3-9adaccf15a17"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 851264 entries, 0 to 851263\n",
            "Data columns (total 7 columns):\n",
            "date      851264 non-null object\n",
            "symbol    851264 non-null object\n",
            "open      851264 non-null float64\n",
            "close     851264 non-null float64\n",
            "low       851264 non-null float64\n",
            "high      851264 non-null float64\n",
            "volume    851264 non-null float64\n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 45.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data.drop(['date','symbol'],axis =1,inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "3d89b110-d0f2-4c93-dd94-10e1f80d9c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
        "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {}
      },
      "source": [
        "data_df = data.iloc[0:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHiuQpg6zDcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6ade03f-1479-404a-b4e5-a4c82c14dd48"
      },
      "source": [
        "data_df.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axjwmt80zOtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "2b90d06e-8e27-4c5a-e20c-ed5b8a807953"
      },
      "source": [
        "data_df['volume'] = data_df['volume'] / 1000000"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTdEhXXTztL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "caf88a15-6f13-4e3f-9abe-533a85139540"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2.1636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2.3864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2.4895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2.0063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1.4086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high  volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2.1636\n",
              "1  125.239998  119.980003  119.940002  125.540001  2.3864\n",
              "2  116.379997  114.949997  114.930000  119.739998  2.4895\n",
              "3  115.480003  116.620003  113.500000  117.440002  2.0063\n",
              "4  117.010002  114.970001  114.089996  117.330002  1.4086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA9gkeTd0E7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data_df['volume']\n",
        "x = data_df.drop(['volume'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmgbHnsP0dLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "060123ea-1fee-40ea-ed1b-f482f6bca4de"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 4), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4LE4U8lTdQJq",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqW2VJcSz2Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size = 0.3, random_state =5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYK-aUuLbrz2"
      },
      "source": [
        "#### Convert Training and Test Data to numpy float32 arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ao-S0tQGcncz",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "train_x =np.array(train_x).astype('float32')\n",
        "test_x = np.array(test_x).astype('float32')\n",
        "train_y =np.array(train_y).astype('float32')\n",
        "test_y = np.array(test_y).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vp9ttNH7e_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y=train_y.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xDIsZDD7g9U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c100faf7-2ca0-4312-b7a0-2d34677547e1"
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "im1ZegbDdKgv"
      },
      "source": [
        "### Normalize the data\n",
        "You can use Normalizer from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "transformer = Normalizer()\n",
        "train_x = transformer.fit_transform(train_x)\n",
        "test_x = transformer.transform(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the Model in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Input-Hidden Layer)\n",
        "w1 = tf.random_normal(shape=(4,2))\n",
        "b1 = tf.zeros(shape=(2)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux23s7EC7w6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Hidden-Output)\n",
        "w2 = tf.random_normal(shape=(2,1))\n",
        "b2 = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlEObGNp6S1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "2.Define a function to calculate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def prediction(x, w1, b1,w2,b2):\n",
        "    \n",
        "    xw_matmul = tf.matmul(x, w1)\n",
        "    net1 = tf.add(xw_matmul, b1)\n",
        "    y=tf.sigmoid(net1)\n",
        "    net2=tf.matmul(y, w2)+b2\n",
        "    out=tf.sigmoid(net2)\n",
        "    return net2,out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "3.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def loss(predicted_y, desired_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - desired_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "4.Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "def train(train_x, train_y, w1, b1,w2,b2, learning_rate=0.01):\n",
        "    \n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "        \n",
        "        t.watch([w1,b1,w2,b2])\n",
        "        \n",
        "        net2,current_prediction = prediction(train_x, w1, b1,w2,b2)\n",
        "        #current_loss =tf.nn.sigmoid_cross_entropy_with_logits(labels = train_y,logits =net2 )\n",
        "        current_loss = loss(net2, train_y)\n",
        "        print(current_loss)\n",
        "    \n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw1,db1,dw2,db2 = t.gradient(current_loss,[w1, b1,w2,b2])\n",
        "    \n",
        "    #Update Weights at output layer\n",
        "    w2 = w2 - learning_rate*dw2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    \n",
        "     #Update Weights at hidden layer\n",
        "    w1 = w1 - learning_rate*dw1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "\n",
        "    #print(\"Loss at step {:d}: {:.3f}\".format(i, currentloss)\n",
        "    \n",
        "    return w1, b1,w2,b2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Train the model for 100 epochs \n",
        "1. Observe the training loss at every iteration\n",
        "2. Observe Train loss at every 5th iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e653bf31-2424-4d47-f136-57431e9dbf5a"
      },
      "source": [
        "for i in range(100):\n",
        "    \n",
        "    w1,b1,w2,b2 = train(train_x, train_y, w1, b1,w2,b2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(255.76656, shape=(), dtype=float32)\n",
            "tf.Tensor(254.59814, shape=(), dtype=float32)\n",
            "tf.Tensor(253.47589, shape=(), dtype=float32)\n",
            "tf.Tensor(252.3978, shape=(), dtype=float32)\n",
            "tf.Tensor(251.36201, shape=(), dtype=float32)\n",
            "tf.Tensor(250.36688, shape=(), dtype=float32)\n",
            "tf.Tensor(249.41075, shape=(), dtype=float32)\n",
            "tf.Tensor(248.49232, shape=(), dtype=float32)\n",
            "tf.Tensor(247.6101, shape=(), dtype=float32)\n",
            "tf.Tensor(246.76286, shape=(), dtype=float32)\n",
            "tf.Tensor(245.94957, shape=(), dtype=float32)\n",
            "tf.Tensor(245.16913, shape=(), dtype=float32)\n",
            "tf.Tensor(244.42052, shape=(), dtype=float32)\n",
            "tf.Tensor(243.70293, shape=(), dtype=float32)\n",
            "tf.Tensor(243.01543, shape=(), dtype=float32)\n",
            "tf.Tensor(242.35724, shape=(), dtype=float32)\n",
            "tf.Tensor(241.72766, shape=(), dtype=float32)\n",
            "tf.Tensor(241.1259, shape=(), dtype=float32)\n",
            "tf.Tensor(240.55125, shape=(), dtype=float32)\n",
            "tf.Tensor(240.00304, shape=(), dtype=float32)\n",
            "tf.Tensor(239.48058, shape=(), dtype=float32)\n",
            "tf.Tensor(238.98323, shape=(), dtype=float32)\n",
            "tf.Tensor(238.51024, shape=(), dtype=float32)\n",
            "tf.Tensor(238.0609, shape=(), dtype=float32)\n",
            "tf.Tensor(237.6346, shape=(), dtype=float32)\n",
            "tf.Tensor(237.23058, shape=(), dtype=float32)\n",
            "tf.Tensor(236.8481, shape=(), dtype=float32)\n",
            "tf.Tensor(236.48639, shape=(), dtype=float32)\n",
            "tf.Tensor(236.14471, shape=(), dtype=float32)\n",
            "tf.Tensor(235.82239, shape=(), dtype=float32)\n",
            "tf.Tensor(235.51842, shape=(), dtype=float32)\n",
            "tf.Tensor(235.23232, shape=(), dtype=float32)\n",
            "tf.Tensor(234.96317, shape=(), dtype=float32)\n",
            "tf.Tensor(234.71016, shape=(), dtype=float32)\n",
            "tf.Tensor(234.47267, shape=(), dtype=float32)\n",
            "tf.Tensor(234.24986, shape=(), dtype=float32)\n",
            "tf.Tensor(234.04105, shape=(), dtype=float32)\n",
            "tf.Tensor(233.84547, shape=(), dtype=float32)\n",
            "tf.Tensor(233.66248, shape=(), dtype=float32)\n",
            "tf.Tensor(233.49132, shape=(), dtype=float32)\n",
            "tf.Tensor(233.33131, shape=(), dtype=float32)\n",
            "tf.Tensor(233.18199, shape=(), dtype=float32)\n",
            "tf.Tensor(233.0425, shape=(), dtype=float32)\n",
            "tf.Tensor(232.91246, shape=(), dtype=float32)\n",
            "tf.Tensor(232.7912, shape=(), dtype=float32)\n",
            "tf.Tensor(232.67825, shape=(), dtype=float32)\n",
            "tf.Tensor(232.57297, shape=(), dtype=float32)\n",
            "tf.Tensor(232.47502, shape=(), dtype=float32)\n",
            "tf.Tensor(232.38388, shape=(), dtype=float32)\n",
            "tf.Tensor(232.29909, shape=(), dtype=float32)\n",
            "tf.Tensor(232.22023, shape=(), dtype=float32)\n",
            "tf.Tensor(232.14694, shape=(), dtype=float32)\n",
            "tf.Tensor(232.07886, shape=(), dtype=float32)\n",
            "tf.Tensor(232.01558, shape=(), dtype=float32)\n",
            "tf.Tensor(231.95683, shape=(), dtype=float32)\n",
            "tf.Tensor(231.90228, shape=(), dtype=float32)\n",
            "tf.Tensor(231.85172, shape=(), dtype=float32)\n",
            "tf.Tensor(231.80467, shape=(), dtype=float32)\n",
            "tf.Tensor(231.76123, shape=(), dtype=float32)\n",
            "tf.Tensor(231.72078, shape=(), dtype=float32)\n",
            "tf.Tensor(231.68332, shape=(), dtype=float32)\n",
            "tf.Tensor(231.64854, shape=(), dtype=float32)\n",
            "tf.Tensor(231.61638, shape=(), dtype=float32)\n",
            "tf.Tensor(231.58647, shape=(), dtype=float32)\n",
            "tf.Tensor(231.55894, shape=(), dtype=float32)\n",
            "tf.Tensor(231.53323, shape=(), dtype=float32)\n",
            "tf.Tensor(231.50958, shape=(), dtype=float32)\n",
            "tf.Tensor(231.48755, shape=(), dtype=float32)\n",
            "tf.Tensor(231.46724, shape=(), dtype=float32)\n",
            "tf.Tensor(231.44835, shape=(), dtype=float32)\n",
            "tf.Tensor(231.43094, shape=(), dtype=float32)\n",
            "tf.Tensor(231.41478, shape=(), dtype=float32)\n",
            "tf.Tensor(231.39978, shape=(), dtype=float32)\n",
            "tf.Tensor(231.38596, shape=(), dtype=float32)\n",
            "tf.Tensor(231.37315, shape=(), dtype=float32)\n",
            "tf.Tensor(231.36131, shape=(), dtype=float32)\n",
            "tf.Tensor(231.35034, shape=(), dtype=float32)\n",
            "tf.Tensor(231.34018, shape=(), dtype=float32)\n",
            "tf.Tensor(231.33081, shape=(), dtype=float32)\n",
            "tf.Tensor(231.32214, shape=(), dtype=float32)\n",
            "tf.Tensor(231.31409, shape=(), dtype=float32)\n",
            "tf.Tensor(231.30663, shape=(), dtype=float32)\n",
            "tf.Tensor(231.29977, shape=(), dtype=float32)\n",
            "tf.Tensor(231.29341, shape=(), dtype=float32)\n",
            "tf.Tensor(231.28755, shape=(), dtype=float32)\n",
            "tf.Tensor(231.28206, shape=(), dtype=float32)\n",
            "tf.Tensor(231.2771, shape=(), dtype=float32)\n",
            "tf.Tensor(231.27242, shape=(), dtype=float32)\n",
            "tf.Tensor(231.26808, shape=(), dtype=float32)\n",
            "tf.Tensor(231.26418, shape=(), dtype=float32)\n",
            "tf.Tensor(231.2604, shape=(), dtype=float32)\n",
            "tf.Tensor(231.2571, shape=(), dtype=float32)\n",
            "tf.Tensor(231.2539, shape=(), dtype=float32)\n",
            "tf.Tensor(231.25105, shape=(), dtype=float32)\n",
            "tf.Tensor(231.24835, shape=(), dtype=float32)\n",
            "tf.Tensor(231.24585, shape=(), dtype=float32)\n",
            "tf.Tensor(231.24355, shape=(), dtype=float32)\n",
            "tf.Tensor(231.24141, shape=(), dtype=float32)\n",
            "tf.Tensor(231.2395, shape=(), dtype=float32)\n",
            "tf.Tensor(231.23766, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkMY3d5fBzSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "c0c4eb6d-2080-4640-d862-be4b59f5d5ae"
      },
      "source": [
        "for i in range(0,100,5):\n",
        "    print(i)\n",
        "    w1,b1,w2,b2 = train(train_x, train_y, w1, b1,w2,b2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "tf.Tensor(231.23598, shape=(), dtype=float32)\n",
            "5\n",
            "tf.Tensor(231.23451, shape=(), dtype=float32)\n",
            "10\n",
            "tf.Tensor(231.23299, shape=(), dtype=float32)\n",
            "15\n",
            "tf.Tensor(231.23169, shape=(), dtype=float32)\n",
            "20\n",
            "tf.Tensor(231.23045, shape=(), dtype=float32)\n",
            "25\n",
            "tf.Tensor(231.22928, shape=(), dtype=float32)\n",
            "30\n",
            "tf.Tensor(231.2283, shape=(), dtype=float32)\n",
            "35\n",
            "tf.Tensor(231.2273, shape=(), dtype=float32)\n",
            "40\n",
            "tf.Tensor(231.22638, shape=(), dtype=float32)\n",
            "45\n",
            "tf.Tensor(231.22563, shape=(), dtype=float32)\n",
            "50\n",
            "tf.Tensor(231.22484, shape=(), dtype=float32)\n",
            "55\n",
            "tf.Tensor(231.22415, shape=(), dtype=float32)\n",
            "60\n",
            "tf.Tensor(231.22342, shape=(), dtype=float32)\n",
            "65\n",
            "tf.Tensor(231.22284, shape=(), dtype=float32)\n",
            "70\n",
            "tf.Tensor(231.2223, shape=(), dtype=float32)\n",
            "75\n",
            "tf.Tensor(231.22173, shape=(), dtype=float32)\n",
            "80\n",
            "tf.Tensor(231.2213, shape=(), dtype=float32)\n",
            "85\n",
            "tf.Tensor(231.22092, shape=(), dtype=float32)\n",
            "90\n",
            "tf.Tensor(231.22047, shape=(), dtype=float32)\n",
            "95\n",
            "tf.Tensor(231.22005, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "2d60d066-c520-4d37-87b7-f859a238978b"
      },
      "source": [
        "w1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=6495, shape=(4, 2), dtype=float32, numpy=\n",
              "array([[-0.04754365, -1.6142803 ],\n",
              "       [ 0.7270954 , -1.23668   ],\n",
              "       [ 0.82412225, -1.0792744 ],\n",
              "       [-0.6058177 , -0.20622554]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTsPbqufCr9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "60f7781a-c8d3-4c84-e6f1-d21694dd202e"
      },
      "source": [
        "w1.shape,w2.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([Dimension(4), Dimension(2)]),\n",
              " TensorShape([Dimension(2), Dimension(1)]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "abf14c5a-716f-477b-d4f0-6cbea3487bdc"
      },
      "source": [
        "w2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=6489, shape=(2, 1), dtype=float32, numpy=\n",
              "array([[ 2.384499  ],\n",
              "       [-0.12639166]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urcqnYiuDBEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4d49d9b-4b77-4e31-86c4-bc41165adf4d"
      },
      "source": [
        "b1"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=6498, shape=(2,), dtype=float32, numpy=array([ 0.95163095, -0.09629563], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qVcF_YDEzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa8e3c24-f3f1-41a1-8cbe-8d8858979978"
      },
      "source": [
        "b2"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=6492, shape=(1,), dtype=float32, numpy=array([3.162468], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERq9GOKKciho"
      },
      "source": [
        "### Model Prediction on 1st Examples in Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKGvUWahcihp",
        "colab": {}
      },
      "source": [
        "y_pred,current_prediction = prediction(test_x, w1, b1,w2,b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT1rKwMXGigK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5921c70e-c4c8-4eaf-89a1-8b79ab168832"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=6518, shape=(300, 1), dtype=float32, numpy=\n",
              "array([[5.060862 ],\n",
              "       [5.059683 ],\n",
              "       [5.060196 ],\n",
              "       [5.0599804],\n",
              "       [5.0596924],\n",
              "       [5.0610623],\n",
              "       [5.059669 ],\n",
              "       [5.052343 ],\n",
              "       [5.0592055],\n",
              "       [5.0609055],\n",
              "       [5.0614595],\n",
              "       [5.060857 ],\n",
              "       [5.059287 ],\n",
              "       [5.059361 ],\n",
              "       [5.0606313],\n",
              "       [5.057459 ],\n",
              "       [5.0598683],\n",
              "       [5.060356 ],\n",
              "       [5.05824  ],\n",
              "       [5.0610476],\n",
              "       [5.057955 ],\n",
              "       [5.060362 ],\n",
              "       [5.060951 ],\n",
              "       [5.060331 ],\n",
              "       [5.0550494],\n",
              "       [5.059725 ],\n",
              "       [5.0587068],\n",
              "       [5.059736 ],\n",
              "       [5.060684 ],\n",
              "       [5.060588 ],\n",
              "       [5.059203 ],\n",
              "       [5.060536 ],\n",
              "       [5.060354 ],\n",
              "       [5.059995 ],\n",
              "       [5.061109 ],\n",
              "       [5.0615034],\n",
              "       [5.06066  ],\n",
              "       [5.0593824],\n",
              "       [5.0610933],\n",
              "       [5.0607567],\n",
              "       [5.0609093],\n",
              "       [5.06099  ],\n",
              "       [5.061557 ],\n",
              "       [5.060201 ],\n",
              "       [5.060755 ],\n",
              "       [5.0611367],\n",
              "       [5.054666 ],\n",
              "       [5.059435 ],\n",
              "       [5.052327 ],\n",
              "       [5.0581455],\n",
              "       [5.057721 ],\n",
              "       [5.0596857],\n",
              "       [5.0605206],\n",
              "       [5.0522556],\n",
              "       [5.0525293],\n",
              "       [5.058535 ],\n",
              "       [5.0584655],\n",
              "       [5.0599265],\n",
              "       [5.0600896],\n",
              "       [5.0591455],\n",
              "       [5.060397 ],\n",
              "       [5.0600286],\n",
              "       [5.0527716],\n",
              "       [5.0614686],\n",
              "       [5.057807 ],\n",
              "       [5.06036  ],\n",
              "       [5.060166 ],\n",
              "       [5.060088 ],\n",
              "       [5.060036 ],\n",
              "       [5.0612216],\n",
              "       [5.058977 ],\n",
              "       [5.0587735],\n",
              "       [5.058754 ],\n",
              "       [5.059648 ],\n",
              "       [5.058155 ],\n",
              "       [5.056793 ],\n",
              "       [5.058479 ],\n",
              "       [5.0598335],\n",
              "       [5.060302 ],\n",
              "       [5.0607595],\n",
              "       [5.0602508],\n",
              "       [5.060806 ],\n",
              "       [5.0608234],\n",
              "       [5.0601015],\n",
              "       [5.0586767],\n",
              "       [5.0611353],\n",
              "       [5.060351 ],\n",
              "       [5.059246 ],\n",
              "       [5.0609207],\n",
              "       [5.0602746],\n",
              "       [5.059666 ],\n",
              "       [5.060441 ],\n",
              "       [5.060322 ],\n",
              "       [5.060371 ],\n",
              "       [5.0589514],\n",
              "       [5.0601726],\n",
              "       [5.060636 ],\n",
              "       [5.0593433],\n",
              "       [5.0594606],\n",
              "       [5.060854 ],\n",
              "       [5.0609684],\n",
              "       [5.06111  ],\n",
              "       [5.0599318],\n",
              "       [5.060218 ],\n",
              "       [5.057891 ],\n",
              "       [5.0592823],\n",
              "       [5.0569935],\n",
              "       [5.05997  ],\n",
              "       [5.0558963],\n",
              "       [5.056649 ],\n",
              "       [5.060562 ],\n",
              "       [5.0586534],\n",
              "       [5.0583453],\n",
              "       [5.060581 ],\n",
              "       [5.0565414],\n",
              "       [5.059423 ],\n",
              "       [5.0606904],\n",
              "       [5.060079 ],\n",
              "       [5.0612826],\n",
              "       [5.060046 ],\n",
              "       [5.059848 ],\n",
              "       [5.060806 ],\n",
              "       [5.0606055],\n",
              "       [5.056259 ],\n",
              "       [5.058496 ],\n",
              "       [5.060359 ],\n",
              "       [5.0608068],\n",
              "       [5.060345 ],\n",
              "       [5.0607233],\n",
              "       [5.058649 ],\n",
              "       [5.059821 ],\n",
              "       [5.0603046],\n",
              "       [5.06066  ],\n",
              "       [5.0602965],\n",
              "       [5.0568724],\n",
              "       [5.0610948],\n",
              "       [5.061285 ],\n",
              "       [5.06007  ],\n",
              "       [5.0614266],\n",
              "       [5.0607557],\n",
              "       [5.0617104],\n",
              "       [5.06054  ],\n",
              "       [5.0596075],\n",
              "       [5.0611506],\n",
              "       [5.059739 ],\n",
              "       [5.0606203],\n",
              "       [5.0614967],\n",
              "       [5.0607724],\n",
              "       [5.059474 ],\n",
              "       [5.0612345],\n",
              "       [5.0610747],\n",
              "       [5.0602465],\n",
              "       [5.0571175],\n",
              "       [5.060014 ],\n",
              "       [5.060556 ],\n",
              "       [5.0576315],\n",
              "       [5.0615363],\n",
              "       [5.0608797],\n",
              "       [5.0614195],\n",
              "       [5.05997  ],\n",
              "       [5.056584 ],\n",
              "       [5.0602307],\n",
              "       [5.060557 ],\n",
              "       [5.0597835],\n",
              "       [5.059607 ],\n",
              "       [5.0608234],\n",
              "       [5.05305  ],\n",
              "       [5.0590963],\n",
              "       [5.059476 ],\n",
              "       [5.0604424],\n",
              "       [5.0605564],\n",
              "       [5.0552897],\n",
              "       [5.060153 ],\n",
              "       [5.0603366],\n",
              "       [5.06142  ],\n",
              "       [5.059134 ],\n",
              "       [5.061356 ],\n",
              "       [5.0597734],\n",
              "       [5.055041 ],\n",
              "       [5.058741 ],\n",
              "       [5.05663  ],\n",
              "       [5.060815 ],\n",
              "       [5.060036 ],\n",
              "       [5.059513 ],\n",
              "       [5.0612116],\n",
              "       [5.0603037],\n",
              "       [5.06048  ],\n",
              "       [5.059251 ],\n",
              "       [5.0590844],\n",
              "       [5.0592566],\n",
              "       [5.060283 ],\n",
              "       [5.061303 ],\n",
              "       [5.060023 ],\n",
              "       [5.0600786],\n",
              "       [5.059945 ],\n",
              "       [5.060885 ],\n",
              "       [5.0587797],\n",
              "       [5.060996 ],\n",
              "       [5.0602856],\n",
              "       [5.059763 ],\n",
              "       [5.060202 ],\n",
              "       [5.057357 ],\n",
              "       [5.0612893],\n",
              "       [5.0599484],\n",
              "       [5.0595245],\n",
              "       [5.060691 ],\n",
              "       [5.0571585],\n",
              "       [5.057863 ],\n",
              "       [5.060258 ],\n",
              "       [5.0602694],\n",
              "       [5.0578203],\n",
              "       [5.06005  ],\n",
              "       [5.0615153],\n",
              "       [5.059874 ],\n",
              "       [5.058098 ],\n",
              "       [5.059819 ],\n",
              "       [5.060415 ],\n",
              "       [5.058552 ],\n",
              "       [5.060248 ],\n",
              "       [5.0609508],\n",
              "       [5.057972 ],\n",
              "       [5.058655 ],\n",
              "       [5.0602417],\n",
              "       [5.0609856],\n",
              "       [5.059087 ],\n",
              "       [5.061373 ],\n",
              "       [5.0577965],\n",
              "       [5.055404 ],\n",
              "       [5.061719 ],\n",
              "       [5.0607696],\n",
              "       [5.059506 ],\n",
              "       [5.059139 ],\n",
              "       [5.0586514],\n",
              "       [5.0601025],\n",
              "       [5.0614023],\n",
              "       [5.060501 ],\n",
              "       [5.060257 ],\n",
              "       [5.0608764],\n",
              "       [5.0609336],\n",
              "       [5.059986 ],\n",
              "       [5.060781 ],\n",
              "       [5.059703 ],\n",
              "       [5.0595026],\n",
              "       [5.0580835],\n",
              "       [5.056752 ],\n",
              "       [5.058986 ],\n",
              "       [5.058567 ],\n",
              "       [5.0611434],\n",
              "       [5.0583034],\n",
              "       [5.0588784],\n",
              "       [5.059876 ],\n",
              "       [5.061573 ],\n",
              "       [5.060787 ],\n",
              "       [5.0596614],\n",
              "       [5.0613856],\n",
              "       [5.057638 ],\n",
              "       [5.0606427],\n",
              "       [5.0600786],\n",
              "       [5.0614667],\n",
              "       [5.059047 ],\n",
              "       [5.0568657],\n",
              "       [5.0575175],\n",
              "       [5.0603313],\n",
              "       [5.059967 ],\n",
              "       [5.060183 ],\n",
              "       [5.0607185],\n",
              "       [5.061349 ],\n",
              "       [5.0607295],\n",
              "       [5.059982 ],\n",
              "       [5.0585084],\n",
              "       [5.0589437],\n",
              "       [5.0586386],\n",
              "       [5.057871 ],\n",
              "       [5.0612373],\n",
              "       [5.0602245],\n",
              "       [5.061166 ],\n",
              "       [5.061927 ],\n",
              "       [5.0599465],\n",
              "       [5.0589914],\n",
              "       [5.058247 ],\n",
              "       [5.058889 ],\n",
              "       [5.0606713],\n",
              "       [5.0607014],\n",
              "       [5.059997 ],\n",
              "       [5.059417 ],\n",
              "       [5.06081  ],\n",
              "       [5.0606995],\n",
              "       [5.0608406],\n",
              "       [5.060176 ],\n",
              "       [5.0605183],\n",
              "       [5.060067 ],\n",
              "       [5.0584006],\n",
              "       [5.0613174],\n",
              "       [5.0602555],\n",
              "       [5.059751 ],\n",
              "       [5.059288 ],\n",
              "       [5.060255 ],\n",
              "       [5.060315 ],\n",
              "       [5.059789 ],\n",
              "       [5.0608854]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWgjcFiLHk9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e43cdb6e-1fd5-474d-a330-c3b16a663075"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(test_y,y_pred))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.003112086616862575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "## Classification using tf.Keras\n",
        "\n",
        "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O0g6lorycihf"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xFvb5sRcihg",
        "colab": {}
      },
      "source": [
        "iris = pd.read_csv(\"/content/drive/My Drive/Resid6_NeuralNetworks/LabInternal/11_Iris.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAB--Qdwcihm"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJr5dYnocihm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0e722951-5d57-4134-86d0-caa1bee2bff3"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82tdOg55MWbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = pd.get_dummies(iris['Species'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDH_BRTrQ6Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D95nY5ILcihj"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyMQoLMucihj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a8036be5-920f-4323-9b48-dcf3d89ee35a"
      },
      "source": [
        "x = iris.iloc[:,1:5]\n",
        "x.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "0            5.1           3.5            1.4           0.2\n",
              "1            4.9           3.0            1.4           0.2\n",
              "2            4.7           3.2            1.3           0.2\n",
              "3            4.6           3.1            1.5           0.2\n",
              "4            5.0           3.6            1.4           0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZohuRtANPPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cbb94e5b-a733-4c42-bba8-6f6c8761190d"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "0            1                0               0\n",
              "1            1                0               0\n",
              "2            1                0               0\n",
              "3            1                0               0\n",
              "4            1                0               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b22qpC5xcihr"
      },
      "source": [
        "###  Building Model in tf.keras\n",
        "\n",
        "Build a Linear Classifier model  <br>\n",
        "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
        "2. Apply Softmax on Dense Layer outputs <br>\n",
        "3. Use SGD as Optimizer\n",
        "4. Use categorical_crossentropy as loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POMtsvF4Op1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80f6804c-fe73-4869-e91a-b5e28b563b66"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls32o_cfS9MP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78d4beee-7be9-46ae-b4f5-db6347209489"
      },
      "source": [
        "import numpy\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xznlp45AUnZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRVQ-mlDUQuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mb7uv5oRlo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size = 0.3, random_state =2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5FdzqIKcihw"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4qLEdHPscihx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afaf1e5c-748a-4c3c-fc95-6d5b490bb798"
      },
      "source": [
        "model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=50)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0935 - acc: 0.3524 - val_loss: 1.0932 - val_acc: 0.2889\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 76us/step - loss: 1.0912 - acc: 0.3524 - val_loss: 1.0912 - val_acc: 0.2889\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 80us/step - loss: 1.0888 - acc: 0.3524 - val_loss: 1.0891 - val_acc: 0.2889\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 72us/step - loss: 1.0862 - acc: 0.3524 - val_loss: 1.0880 - val_acc: 0.2889\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 73us/step - loss: 1.0847 - acc: 0.3524 - val_loss: 1.0871 - val_acc: 0.2889\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 75us/step - loss: 1.0831 - acc: 0.3524 - val_loss: 1.0861 - val_acc: 0.2889\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 73us/step - loss: 1.0817 - acc: 0.3524 - val_loss: 1.0851 - val_acc: 0.2889\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 75us/step - loss: 1.0800 - acc: 0.3524 - val_loss: 1.0839 - val_acc: 0.2889\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 84us/step - loss: 1.0784 - acc: 0.3524 - val_loss: 1.0827 - val_acc: 0.2889\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 74us/step - loss: 1.0769 - acc: 0.3524 - val_loss: 1.0813 - val_acc: 0.2889\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 77us/step - loss: 1.0752 - acc: 0.3524 - val_loss: 1.0799 - val_acc: 0.2889\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 72us/step - loss: 1.0731 - acc: 0.3524 - val_loss: 1.0784 - val_acc: 0.2889\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 91us/step - loss: 1.0711 - acc: 0.3524 - val_loss: 1.0768 - val_acc: 0.2889\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 76us/step - loss: 1.0690 - acc: 0.3524 - val_loss: 1.0752 - val_acc: 0.2889\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 82us/step - loss: 1.0667 - acc: 0.3524 - val_loss: 1.0735 - val_acc: 0.2889\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 99us/step - loss: 1.0641 - acc: 0.3524 - val_loss: 1.0717 - val_acc: 0.2889\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 95us/step - loss: 1.0615 - acc: 0.3524 - val_loss: 1.0697 - val_acc: 0.2889\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 110us/step - loss: 1.0588 - acc: 0.3524 - val_loss: 1.0676 - val_acc: 0.2889\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 134us/step - loss: 1.0556 - acc: 0.3524 - val_loss: 1.0655 - val_acc: 0.2889\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 79us/step - loss: 1.0527 - acc: 0.3524 - val_loss: 1.0632 - val_acc: 0.2889\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 120us/step - loss: 1.0497 - acc: 0.3524 - val_loss: 1.0608 - val_acc: 0.2889\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 93us/step - loss: 1.0465 - acc: 0.3524 - val_loss: 1.0587 - val_acc: 0.2889\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 82us/step - loss: 1.0424 - acc: 0.3524 - val_loss: 1.0562 - val_acc: 0.2889\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 100us/step - loss: 1.0389 - acc: 0.3524 - val_loss: 1.0539 - val_acc: 0.2889\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 90us/step - loss: 1.0352 - acc: 0.3524 - val_loss: 1.0511 - val_acc: 0.2889\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 124us/step - loss: 1.0316 - acc: 0.3524 - val_loss: 1.0480 - val_acc: 0.2889\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 137us/step - loss: 1.0282 - acc: 0.3524 - val_loss: 1.0445 - val_acc: 0.2889\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 99us/step - loss: 1.0247 - acc: 0.3524 - val_loss: 1.0413 - val_acc: 0.2889\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 113us/step - loss: 1.0213 - acc: 0.3524 - val_loss: 1.0375 - val_acc: 0.2889\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 104us/step - loss: 1.0172 - acc: 0.3524 - val_loss: 1.0343 - val_acc: 0.2889\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 142us/step - loss: 1.0134 - acc: 0.3524 - val_loss: 1.0311 - val_acc: 0.2889\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 95us/step - loss: 1.0082 - acc: 0.3524 - val_loss: 1.0271 - val_acc: 0.2889\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 91us/step - loss: 1.0043 - acc: 0.3524 - val_loss: 1.0224 - val_acc: 0.2889\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 86us/step - loss: 0.9999 - acc: 0.3619 - val_loss: 1.0191 - val_acc: 0.2889\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 119us/step - loss: 0.9947 - acc: 0.3524 - val_loss: 1.0154 - val_acc: 0.2889\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 93us/step - loss: 0.9904 - acc: 0.3524 - val_loss: 1.0112 - val_acc: 0.2889\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 129us/step - loss: 0.9851 - acc: 0.3619 - val_loss: 1.0059 - val_acc: 0.2889\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 108us/step - loss: 0.9804 - acc: 0.3619 - val_loss: 1.0005 - val_acc: 0.3111\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 94us/step - loss: 0.9746 - acc: 0.3714 - val_loss: 0.9950 - val_acc: 0.3111\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 106us/step - loss: 0.9693 - acc: 0.4190 - val_loss: 0.9891 - val_acc: 0.4222\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 108us/step - loss: 0.9634 - acc: 0.5143 - val_loss: 0.9827 - val_acc: 0.5333\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 121us/step - loss: 0.9582 - acc: 0.6190 - val_loss: 0.9788 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 139us/step - loss: 0.9536 - acc: 0.6000 - val_loss: 0.9737 - val_acc: 0.5333\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 132us/step - loss: 0.9469 - acc: 0.6190 - val_loss: 0.9684 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 119us/step - loss: 0.9416 - acc: 0.6286 - val_loss: 0.9632 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 104us/step - loss: 0.9366 - acc: 0.6381 - val_loss: 0.9584 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 99us/step - loss: 0.9312 - acc: 0.6571 - val_loss: 0.9577 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 85us/step - loss: 0.9254 - acc: 0.6095 - val_loss: 0.9511 - val_acc: 0.5333\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 102us/step - loss: 0.9202 - acc: 0.6286 - val_loss: 0.9451 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 102us/step - loss: 0.9160 - acc: 0.6571 - val_loss: 0.9399 - val_acc: 0.5556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f30b5fcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-SgSSdRcih5"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBgKZkhkcih6",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__cR2-c8Wme9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "61bf6dcc-4089-41c9-ff5b-6aea9c135881"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3543337 , 0.3341378 , 0.31152844],\n",
              "       [0.345372  , 0.33660108, 0.31802693],\n",
              "       [0.1512675 , 0.35948396, 0.4892485 ],\n",
              "       [0.35105348, 0.33500454, 0.313942  ],\n",
              "       [0.33183756, 0.34017304, 0.32798934],\n",
              "       [0.14079489, 0.3583761 , 0.50082904],\n",
              "       [0.33807698, 0.3384774 , 0.32344562],\n",
              "       [0.13185188, 0.35643065, 0.51171756],\n",
              "       [0.13628949, 0.35735112, 0.5063594 ],\n",
              "       [0.3453855 , 0.33654547, 0.31806907],\n",
              "       [0.35679203, 0.33335084, 0.30985713],\n",
              "       [0.3566358 , 0.33351225, 0.3098519 ],\n",
              "       [0.3567875 , 0.33335555, 0.30985698],\n",
              "       [0.34727728, 0.3359887 , 0.31673405],\n",
              "       [0.18720298, 0.3619327 , 0.45086434],\n",
              "       [0.17668858, 0.36161622, 0.46169516],\n",
              "       [0.33500797, 0.33930525, 0.32568675],\n",
              "       [0.19604144, 0.3617579 , 0.4422007 ],\n",
              "       [0.13345282, 0.3569236 , 0.5096235 ],\n",
              "       [0.19697137, 0.3616295 , 0.44139916],\n",
              "       [0.162934  , 0.36092505, 0.47614092],\n",
              "       [0.19240348, 0.36172536, 0.44587117],\n",
              "       [0.14649211, 0.3591082 , 0.4943997 ],\n",
              "       [0.19290912, 0.3618178 , 0.44527313],\n",
              "       [0.17983782, 0.3615082 , 0.458654  ],\n",
              "       [0.34251484, 0.33736435, 0.32012075],\n",
              "       [0.3567049 , 0.3334409 , 0.30985424],\n",
              "       [0.16438232, 0.3610348 , 0.47458285],\n",
              "       [0.334998  , 0.33931643, 0.3256855 ],\n",
              "       [0.13463935, 0.3573413 , 0.5080194 ],\n",
              "       [0.16477938, 0.3609396 , 0.47428104],\n",
              "       [0.3312791 , 0.34022808, 0.32849276],\n",
              "       [0.2185976 , 0.3603724 , 0.42102998],\n",
              "       [0.11771961, 0.35358283, 0.52869755],\n",
              "       [0.18312015, 0.36194563, 0.45493424],\n",
              "       [0.35693347, 0.33320472, 0.30986175],\n",
              "       [0.13478088, 0.35703272, 0.50818634],\n",
              "       [0.18153994, 0.36191097, 0.4565491 ],\n",
              "       [0.19383463, 0.36158568, 0.44457966],\n",
              "       [0.1510294 , 0.3595857 , 0.48938483],\n",
              "       [0.18157785, 0.36182246, 0.4565997 ],\n",
              "       [0.19241723, 0.36176705, 0.44581568],\n",
              "       [0.12993325, 0.3562291 , 0.5138377 ],\n",
              "       [0.22671549, 0.3596933 , 0.41359124],\n",
              "       [0.34694472, 0.3361614 , 0.31689385]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUac08yQaSZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "50cf308d-bfbc-458e-8df5-cb61b602a0a7"
      },
      "source": [
        "#y_test_class = np.argmax(test_y,axis = 1)\n",
        "y_pred_class = np.argmax(y_pred, axis = 1)\n",
        "y_pred_class"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 0, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQk5dn0eevhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a054705f-b0b9-44aa-ccb8-5c6bc17b97cf"
      },
      "source": [
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 127us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.939855408668518, 0.5555555562178294]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P32ASP1Vjt0a"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8rd0jjAjyTR",
        "colab": {}
      },
      "source": [
        "model.save('Iris_model.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiipRpe7rbVh"
      },
      "source": [
        "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
        "\n",
        "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5Du3lubr4sA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2idTMzjyWaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}